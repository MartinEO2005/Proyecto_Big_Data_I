#!/usr/bin/env python3
"""
catalog_query.py

Consulta el catálogo OData de Copernicus tomando parámetros desde VARIABLES DE ENTORNO.
Guarda metadatos en JSON y CSV en la carpeta OUTDIR.

Variables de entorno (ejemplos):
  COP_S3_KEY, COP_S3_SECRET, COP_S3_ENDPOINT, COP_S3_BUCKET   (opcionales, aquí no usadas)
  CDSE_USER, CDSE_PASS   (opcional: si están, se intentará obtener token Keycloak)
  COLLECTION             (ej: SENTINEL-5P, SENTINEL-2)
  AOI_WKT                (opcional WKT: "POLYGON((lon lat, ...))")
  DATE_FROM              (YYYY-MM-DD)
  DATE_TO                (YYYY-MM-DD)
  MAX_CLOUD              (opcional, sólo para SENTINEL-2)
  OUTDIR                 (ej: ./catalog_output)
  TOP                    (nº elementos por página OData; opcional)
"""

import os
import json
import requests
import pandas as pd
from datetime import datetime

CATALOG_BASE = "https://catalogue.dataspace.copernicus.eu/odata/v1/Products"

def get_keycloak_token_if_available():
    user = os.getenv("CDSE_USER")
    pwd = os.getenv("CDSE_PASS")
    if not user or not pwd:
        return None
    try:
        resp = requests.post(
            "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token",
            data={"client_id":"cdse-public","username":user,"password":pwd,"grant_type":"password"},
            timeout=30
        )
        resp.raise_for_status()
        return resp.json().get("access_token")
    except Exception as e:
        print("⚠️  No se pudo generar token Keycloak (se seguirá sin auth):", e)
        return None

def build_filter(collection, date_from, date_to, aoi_wkt=None, cloud=None):
    base = (
        f"Collection/Name eq '{collection}' and "
        f"ContentDate/Start ge {date_from}T00:00:00.000Z and "
        f"ContentDate/Start le {date_to}T23:59:59.999Z"
    )
    if aoi_wkt:
        base = (
            f"Collection/Name eq '{collection}' and "
            f"OData.CSC.Intersects(area=geography'SRID=4326;{aoi_wkt}') and "
            f"ContentDate/Start ge {date_from}T00:00:00.000Z and "
            f"ContentDate/Start le {date_to}T23:59:59.999Z"
        )
    if cloud and "SENTINEL-2" in collection.upper():
        base += f" and Attributes/any(a: a/Name eq 'CloudCover' and a/Value le {int(cloud)})"
    return base

def query_catalog(filter_expr, top=500, auth_token=None):
    q = f"{CATALOG_BASE}?$filter={filter_expr}&$count=True&$top={top}"
    headers = {"Accept": "application/json"}
    if auth_token:
        headers["Authorization"] = f"Bearer {auth_token}"
    items = []
    while q:
        print("Consultando:", q)
        r = requests.get(q, headers=headers, timeout=60)
        if r.status_code != 200:
            print("ERROR en consulta (status):", r.status_code)
            try:
                print("Respuesta (parcial):", r.text[:1000])
            except Exception:
                pass
            r.raise_for_status()
        js = r.json()
        page = js.get("value", [])
        items.extend(page)
        q = js.get("@odata.nextLink")
    return items

def items_to_dataframe(items):
    if not items:
        return pd.DataFrame()
    df = pd.json_normalize(items)
    if "Name" in df.columns:
        df["identifier"] = df["Name"].astype(str).str.split(".").str[0]
    if "ContentDate.Start" in df.columns:
        df["content_start"] = pd.to_datetime(df["ContentDate.Start"])
    else:
        df["content_start"] = pd.to_datetime(df.get("ContentDate", pd.NA).apply(lambda x: x.get("Start") if isinstance(x, dict) else None))
    if "CloudCover" in df.columns:
        df["cloudcover"] = df["CloudCover"]
    else:
        if "Attributes" in df.columns:
            def find_cloud(attrs):
                if isinstance(attrs, list):
                    for a in attrs:
                        if isinstance(a, dict):
                            name = str(a.get("Name","")).lower()
                            if "cloud" in name:
                                return a.get("Value") or a.get("value") or a.get("doubleValue") or None
                return None
            df["cloudcover"] = df["Attributes"].apply(find_cloud)
        else:
            df["cloudcover"] = None
    return df

def save_items(items, df, outdir, collection, date_from, date_to):
    os.makedirs(outdir, exist_ok=True)
    base = f"{collection}_{date_from}_to_{date_to}"
    json_path = os.path.join(outdir, base + ".json")
    csv_path = os.path.join(outdir, base + ".csv")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)
    cols = [c for c in ["Id","Name","identifier","content_start","IngestionDate","cloudcover","sizeInBytes"] if c in df.columns]
    if cols:
        df[cols].to_csv(csv_path, index=False)
    else:
        df.to_csv(csv_path, index=False)
    return json_path, csv_path

def main():
    # Leer variables de entorno (defaults si no están)
    COLLECTION = os.getenv("COLLECTION", "SENTINEL-5P")
    AOI_WKT = os.getenv("AOI_WKT", None)  # incluir si quieres
    DATE_FROM = os.getenv("DATE_FROM", (datetime.utcnow().date().replace(year=datetime.utcnow().year-1)).isoformat())
    DATE_TO = os.getenv("DATE_TO", datetime.utcnow().date().isoformat())
    MAX_CLOUD = os.getenv("MAX_CLOUD", None)
    OUTDIR = os.getenv("OUTDIR", "./catalog_output")
    TOP = int(os.getenv("TOP", "500"))

    print(f"Parámetros usados:\n COLLECTION={COLLECTION}\n DATE_FROM={DATE_FROM}\n DATE_TO={DATE_TO}\n AOI={bool(AOI_WKT)}\n MAX_CLOUD={MAX_CLOUD}\n OUTDIR={OUTDIR}\n")

    token = get_keycloak_token_if_available()
    filt = build_filter(COLLECTION, DATE_FROM, DATE_TO, aoi_wkt=AOI_WKT, cloud=MAX_CLOUD)
    try:
        items = query_catalog(filt, top=TOP, auth_token=token)
    except Exception as e:
        print("❌ Error al consultar catálogo:", e)
        return

    print(f"\nTotal items recuperados: {len(items)}")
    df = items_to_dataframe(items)
    json_path, csv_path = save_items(items, df, OUTDIR, COLLECTION, DATE_FROM, DATE_TO)
    print("\n✅ Guardado JSON:", json_path)
    print("✅ Guardado CSV:", csv_path)
    if not df.empty:
        print("\nPrimeras filas (CSV):")
        print(df.head(5).to_string(index=False))

if __name__ == "__main__":
    main()
